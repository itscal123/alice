import sys
import streamlit as st
import time
import torch
from streamlit_chat import message
sys.path.insert(1, "BERT\\")        # Add BERT folder to path
sys.path.insert(1, "generative\\")  # Add generative folder to path

# Information Retrieval model imports
from bert import BertAlice

# Generative model imports
from model import Generative
from train import Encoder, Decoder, GreedySearchDecoder, GlobalAttn, BeamSearchDecoder
from data import Voc, normalizeString, indexesFromSentence, Data

# Load the information retrieval model
bert = BertAlice()
# Load the generative model
generative = Generative()



def get_text():
    """
    Provides the text field for user input. To simulate "entering" a
    sentence, simply wait 1 second then reinitialize the same input_text
    box
    params: None
    returns: input_text (str)
    """
    input_text = st.text_input("You: ", "", key="input")
    return input_text


def bertQuery(input_seq):
    """
    Takes in the input_sequence forom user, then outputs the response
    generated by the bi-encoder model.
    params: input_seq (str)
    returns: response (str)
    """
    return bert.get_response(input_seq)


def generativeQuery(input_seq):
    """
    Takes in the input_sequence from the user, then outputs
    the response generated by the encoder-decoder model.
    params: input_seq (str)
    returns: response (str)
    """
    return generative.response(input_seq)


if __name__ == "__main__":
    # Page configuration
    st.set_page_config(
        page_title = "ALICE - Demo",
        page_icon = ":robot:"
    )
    # Title
    st.header("ALICE - Demo")

    if "responses" not in st.session_state:
        st.session_state["responses"] = []

    if "past" not in st.session_state:
        st.session_state["past"] = []

    # User prompt
    user_input = get_text()

    # Book keeping of all utterances between the user and ALICE.
    if user_input:
        # bi-encoder's query
        score, output = bertQuery(user_input)
        
        # generative's query if bi-encoder's is below threshold
        if not torch.greater(score, torch.tensor(0.7)):
            output = generativeQuery(user_input)

        st.session_state.past.append(user_input)
        st.session_state.responses.append(output)       


    if st.session_state["responses"]:
        for i in range(len(st.session_state["responses"])-1, -1, -1):
            message(st.session_state["responses"][i], key=str(i))
            message(st.session_state["past"][i], is_user=True, key=str(i) + "_user")